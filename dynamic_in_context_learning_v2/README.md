# üöÄ Adaptive In-Context Learning for Spaceship Titanic Prediction

This project implements an advanced machine learning approach for the Kaggle Spaceship Titanic competition using adaptive rule-based prediction with LLM-generated rules and deterministic execution.

## üìã Project Overview

The project explores different strategies for predicting passenger transportation outcomes in the Spaceship Titanic dataset:

1. **LLM-Generated Rules**: Use AI models to analyze data and create predictive rules
2. **Adaptive Learning**: Iteratively refine rules based on prediction errors
3. **Deterministic Execution**: Convert learned rules into deterministic Python logic
4. **Performance Validation**: Test rules on unseen data with various evaluation methods

## üõ†Ô∏è Scripts Overview

### Core Scripts

#### 1. `adaptive_sampling_prediction.py`
**Purpose**: Main adaptive learning script that iteratively improves prediction rules
- **Input**: Spaceship Titanic training data
- **Process**:
  - Loads training data with shuffling for generalization
  - Uses stratified sampling per iteration (default: 200 rows)
  - Generates/adapts rules using LLM (default: deepseek/deepseek-chat-v3.1)
  - Tracks best rules and accuracy across iterations
  - Saves best rules after each improvement
- **Key Features**:
  - Fixed held-out validation set (never enters training)
  - Rolling average plotting for trend visualization
  - Automatic rule saving when new best accuracy is achieved
- **Configuration**:
  - `TRAINING_ROWS`: Rows sampled per iteration (default: 200)
  - `VALIDATION_ROWS`: Fixed validation set size (default: 50)
  - `MAX_ITERATIONS`: Maximum learning iterations (default: 100)
  - `ROLLING_AVERAGE_WINDOW`: Window for trend plotting (default: 5)

#### 2. `predict_from_rules.py`
**Purpose**: Test rules on random samples with parallel evaluation
- **Input**: Rules file path + dataset
- **Process**:
  - Loads specified rules file
  - Samples N rows (stratified by Transported)
  - Runs M parallel predictions on same sample
  - Calculates accuracy for each run
  - Reports individual accuracies + average
- **Key Features**:
  - Parallel processing for stability testing
  - Stratified sampling maintains class balance
  - Automatic path handling (converts backslashes to forward slashes)
  - Saves comprehensive results to JSON
- **Configuration**:
  - `SAMPLE_SIZE`: Number of rows to test (default: 50)
  - `PARALLEL_RUNS`: Number of parallel predictions (default: 5)
  - `RULES_FILE_PATH`: Path to rules file to test

#### 3. `predict_with_deterministic_rules.py`
**Purpose**: Deterministic implementation of 32 learned rules
- **Input**: Full training dataset
- **Process**:
  - Implements 32 rules as pure Python conditionals
  - Handles NaN values properly (treats missing spending as 0)
  - Applies rules in order to each passenger
  - Calculates accuracy on full dataset
- **Key Features**:
  - No API calls required (pure Python logic)
  - Handles missing data gracefully
  - Cabin parsing (deck/side extraction)
  - TotalSpend calculation from all amenities

#### 4. `predict_with_deterministic_rules_93pct.py`
**Purpose**: Deterministic implementation of 36 rules from 93% accuracy model
- **Similar to above but with 36 rules**
- **Enhanced rule set** with more specific conditions
- **Same deterministic approach** but higher accuracy baseline

#### 5. `create_kaggle_submission.py`
**Purpose**: Generate Kaggle submission file from deterministic rules
- **Input**: Training data
- **Process**:
  - Applies deterministic rules to all passengers
  - Creates CSV with PassengerId and Transported predictions
  - Ready for Kaggle submission
- **Output**: `submission.csv` with Kaggle format

### Utility Scripts

#### 6. `simple_adaptive_prediction.py`
**Legacy script**: Original implementation before advanced features
- Basic adaptive learning without advanced sampling
- Good for comparison/testing

## üìä Results and Outputs

### JSON Results Files

#### `accuracies_summary_[avg]pct_avg_[N]_samples_[M]_runs_[timestamp].json`
**Generated by**: `predict_from_rules.py`
```json
{
  "sample_size": 50,
  "parallel_runs": 5,
  "rules_file": "path/to/rules.txt",
  "accuracies": {
    "1": 0.72,
    "2": 0.74,
    "3": 0.76,
    "4": 0.70,
    "5": 0.73
  },
  "average_accuracy": 0.73,
  "successful_runs": 5
}
```
**Purpose**: Tracks performance stability across multiple runs
- Shows individual run accuracies
- Calculates average performance
- Includes metadata about test conditions

#### `accuracy_metrics.json`
**Generated by**: `adaptive_sampling_prediction.py`
```json
{
  "training_rows": 200,
  "validation_rows": 50,
  "accuracy_threshold": 0.95,
  "max_iterations": 100,
  "iterations": [
    {
      "iteration": 1,
      "accuracy": 0.72,
      "best_accuracy": 0.72,
      "timestamp": "2025-09-03 12:30:45",
      "above_threshold": false
    },
    {
      "iteration": 2,
      "accuracy": 0.85,
      "best_accuracy": 0.85,
      "timestamp": "2025-09-03 12:31:12",
      "above_threshold": false
    }
  ]
}
```
**Purpose**: Tracks learning progress over iterations
- Records accuracy for each iteration
- Tracks best accuracy achieved so far
- Timestamps for reproducibility

### Text Files

#### `initial_rules.txt`
**Generated by**: `adaptive_sampling_prediction.py` (iteration 1)
```
PREDICTIVE RULES:

1. Rule description...
2. Another rule...
...
```
**Purpose**: First set of rules generated from initial data analysis

#### `rules_iteration_[N]_[timestamp].txt`
**Generated by**: `adaptive_sampling_prediction.py` (iterations 2+)
```
IMPROVED PREDICTIVE RULES:

1. Enhanced rule based on error analysis...
2. Correction for previous mistakes...
...
```
**Purpose**: Rule improvements based on prediction errors

#### `best_rules_[X]pct_accuracy.txt`
**Generated by**: `adaptive_sampling_prediction.py`
```
BEST PREDICTIVE RULES
==================================================
Accuracy: 93.0%
From Iteration: 8
Generated: 2025-09-03 16:25:49
==================================================

IMPROVED PREDICTIVE RULES:

1. Most effective rule...
...
```
**Purpose**: Best-performing rules with metadata

### PNG Plot Files

#### `accuracy_progress.png`
**Generated by**: `adaptive_sampling_prediction.py`
**Features**:
- **Blue line**: Current iteration accuracies
- **Red line**: Best accuracy progression
- **Purple dashed line**: Rolling average (last N iterations)
- **Green line**: Accuracy threshold
- **Green dots**: Validation results (when available)

**Purpose**: Visualize learning progress and trends
- Shows improvement over iterations
- Rolling average smooths out noise
- Validation points show generalization

### CSV Files

#### `submission.csv`
**Generated by**: `create_kaggle_submission.py`
```csv
PassengerId,Transported
0001_01,False
0001_02,True
0002_01,False
...
```
**Purpose**: Ready-to-submit Kaggle predictions

## üöÄ How to Use

### Basic Usage

1. **Run Adaptive Learning**:
   ```bash
   python adaptive_sampling_prediction.py
   ```

2. **Test Rules on Samples**:
   ```bash
   python predict_from_rules.py
   ```

3. **Create Kaggle Submission**:
   ```bash
   python create_kaggle_submission.py
   ```

### Configuration

Edit the top variables in each script:
- **Model**: Change `MODEL_NAME` for different AI models
- **Sample sizes**: Adjust `TRAINING_ROWS`, `SAMPLE_SIZE`
- **Iterations**: Modify `MAX_ITERATIONS`
- **Rules file**: Update `RULES_FILE_PATH` in testing scripts

### File Organization

```
adaptive_results_[model]_[timestamp]/
‚îú‚îÄ‚îÄ accuracy_metrics.json          # Learning progress
‚îú‚îÄ‚îÄ accuracy_progress.png          # Progress visualization
‚îú‚îÄ‚îÄ initial_rules.txt              # First rules
‚îú‚îÄ‚îÄ rules_iteration_[N]_[time].txt # Rule improvements
‚îú‚îÄ‚îÄ best_rules_[X]pct_accuracy.txt # Best rules
‚îî‚îÄ‚îÄ ...

accuracies_summary_[avg]pct_avg_[N]_samples_[M]_runs_[timestamp].json
submission.csv
```

## üì¶ Dependencies

```bash
pip install pandas openai termcolor matplotlib
```

### Environment Variables
```bash
# For OpenRouter
export OPENROUTER_API_KEY="your_key_here"

# For OpenAI
export OPENAI_API_KEY="your_key_here"
```

## üéØ Key Features

- **Adaptive Rule Learning**: Rules improve iteratively based on errors
- **Stratified Sampling**: Maintains class balance in training/validation
- **Parallel Evaluation**: Tests rule stability across multiple runs
- **Deterministic Implementation**: Rules work without API calls
- **Comprehensive Logging**: All results saved with timestamps
- **Visualization**: Progress plots with trend analysis
- **Kaggle Ready**: Direct submission file generation

## üî¨ Methodology

1. **Data Preparation**: Shuffle and split into training/validation
2. **Rule Generation**: LLM analyzes data and creates initial rules
3. **Iterative Refinement**: Rules adapt based on prediction errors
4. **Validation**: Test on held-out data for generalization
5. **Deterministic Conversion**: Translate learned rules to pure Python
6. **Stability Testing**: Multiple runs to assess consistency
7. **Kaggle Submission**: Generate competition-ready predictions

## üìà Performance Tracking

- **Training Accuracy**: How well rules fit training data
- **Validation Accuracy**: Generalization to unseen data
- **Stability**: Consistency across parallel runs
- **Improvement Rate**: How quickly rules get better
- **Rolling Trends**: Smoothed performance over time

This project demonstrates how LLM-generated rules can be systematically improved and converted into reliable, deterministic prediction systems for tabular data challenges.
