PREDICTIVE METRICS - ITERATION 128
============================================================

Executive summary — immediate takeaways & top priorities (0–72h)
- What happened (short):
  - Two brittle failure modes surfaced in a very small batch:
    - 0167_01 — all spends == 0, CryoSleep = True → model predicted Not‑transported (false negative). Low‑context all_zero+CryoSleep slice; pooled priors & calibrator overstated confidence for an n==1 sample.
    - 0167_02 — RoomService = 1365 (dominant spend), other spends small → model predicted Transported (false positive); actual = Not‑transported. Single‑feature dominance (high RoomService) flipped the logit but historical sign for high single‑channel dominance is noisy.
  - Both occurred in tiny-batch conditions; gating allowed auto‑decisions for fragile records and scorer/calibrator provenance/handling mismatches allowed per‑feature contributions to dominate wrongly.
- Immediate root causes (short):
  - permissive n==1 auto‑decision logic and no stronger batch/cohort checks,
  - pooled priors insufficiently stratified (cryo_all_zero and top1_dom slices not treated as fragile),
  - calibrator under‑estimates uncertainty for low‑context / high‑dominance records,
  - inconsistent treatment of raw zeros vs imputed zeros between scorer → calibrator → gate,
  - no per‑feature cap/sign‑consistency mechanisms so single features (CryoSleep or RoomService) could overwhelm the ensemble,
  - no inter‑record/cohort consistency checks for passengers in same cabin/booking.
- Immediate stopgap (0–6h):
  - Block any n==1 auto‑decision that sets fragile_flag; fragile_flag must include cryo_all_zero_flag and top1_dom_flag (top1_share ≥ 0.60) and imputed_zero_flag/missingness_count ≥ 1. Add 0167_01 and 0167_02 to the canary list. Persist raw spends, imputation provenance and per‑feature contributions to ensure calibrator/gate use identical inputs.

Concise answers to the six questions (batch accuracy focus)
1) What specific patterns caused this error?
- Two patterns: low‑context all_zero+CryoSleep (high uncertainty, historical sign unstable) and single‑channel dominance (very high RoomService) leading to overconfident positive prediction. Both are fragile for n==1 and require larger context/pooled prior or multi‑model consensus.

2) How should decision rules be modified to prevent recurrence?
- Disallow n==1 auto‑decisions for records flagged fragile (cryo_all_zero, top1_dom, imputed_zero, missingness). Require GLM_fallback agreement + ensemble agreement + narrow quantile width + pooled‑prior backing for any single‑record auto‑decide on these slices. Add batch/cohort consistency checks to detect contradictory predictions within same booking/cabin.

3) What new insights about transport patterns?
- CryoSleep’s predictive sign is context dependent (modifier, not global). High spend in a single channel does not universally imply Transported — dominance direction is channel & demographic dependent. Family/cohort relationships (same Cabin/Booking) provide strong priors and should be used to reduce per‑record volatility.

4) How should confidence levels be recalibrated?
- Calibrator must be heteroskedastic and slice‑aware: output p10/p50/p90 and sd, inflate uncertainty for cryo_all_zero, high‑dominance, high missingness and sign‑inconsistency records using var components and SE floors. Use conformalized quantile regression or pinball loss + variance head and add slice‑aware SE floors.

5) What adjustments are needed for batch consistency?
- Persist transformations and provenance; stratify pooled priors by (CryoSleep × all_zero × top1_channel × demo). Add batch checks (batch_frac_fragile threshold) and cohort checks (contradictory predictions within same Cabin/Booking) to hold auto‑decisions. Shadow‑run gating for canaries.

6) How can metrics be improved to handle edge cases?
- Add cryo_all_zero and top1_dom pooled priors, additional variance components (var_cryo_all_zero, var_high_spend), upweight edge cases in retraining, add canary tests and daily slice guards.

Complete updated predictive metrics report — actionable components (optimized for batch accuracy)

A. Feature engineering updates (v→v+1)
- Spend aggregates:
  - sum_spend = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck
  - sum_spend_log = log1p(sum_spend)
  - sum_spend_bucket = [0,50,200,400,600,800,2000+]
- Zero / imputation / missingness:
  - all_zero_flag = (all five spends == 0)
  - cryo_all_zero_flag = (CryoSleep == True AND all_zero_flag)
  - imputed_zero_flag = any spend value was imputed as 0 (requires imputation provenance)
  - missingness_count, missingness_profile (which channels were missing vs true zero)
- Dominance & novelty:
  - top1_channel, top1_spend, top1_share
  - top1_dom_flag = top1_share ≥ TOP1_DOM_THRESHOLD (0.60)
  - spend_entropy_norm, num_nonzero_channels
  - feature_dom_fraction computed from per‑feature logit contributions
  - dominance_sign_consistency_score: historical fraction with same sign for top1_channel & CryoSleep in matching buckets (homeplanet/demographic)
  - high_spend_outlier_flag = top1_spend ≥ TOP1_SPEND_HIGH (400)
  - all_zero_context_score: Mahalanobis/kNN distance of this all_zero record to historical centroids of (transported vs not)
- Cohort / inter‑record:
  - booking_id / cabin_group_id (where available)
  - cohort_transport_consistency_score = fraction transported historically for that booking/cabin group
  - in_batch_cohort_contradiction_flag = conflicting model outputs within same booking/cabin in current batch
- Interactions:
  - CryoSleep × all_zero_flag × HomePlanet, CryoSleep × Cabin_section, CryoSleep × Age_bucket, all_zero_context_score × top1_channel, top1_dom_flag × feature_dom_fraction

B. Pooled priors (cryo‑aware + channel/demographic/family stratified)
- Stratify priors by (CryoSleep, all_zero_flag, top1_channel, top1_share_bucket, HomePlanet, Destination) and where available by cohort (booking/cabin) when N supports it.
- Blend with slice weight τ_slice = N_slice / (N_slice + N0_slice).
- Use larger N0 for fragile slices:
  - N0_cryo_all_zero start = 150
  - N0_top1_dom baseline = 100; increase for channels with high variance (FoodCourt, RoomService) to 150–200.
- Snapshot pooled priors for provenance per deploy.

C. Per‑feature logit caps & sign‑consistency downweighting
- Enforce per‑feature caps to stop single features dominating:
  - CAP_PER_FEATURE_LOGIT: default 3.0 logits; for high‑variance spend features start at 2.5; for CryoSleep consider 2.0–2.5 (sweepable).
- If dominance_sign_consistency_score < SIGN_CONSIST_MIN (0.70), downweight that feature’s contribution by scale = max(0.4, dominance_sign_consistency_score).
- For imputed_zero_flag True: downweight spend‑feature confidence (multiply spend logits by 0.6–0.8).
- For cohort evidence (cohort_transport_consistency_score high): allow modest relaxation of caps for cohort features if cohort size > threshold.

D. Variance / SE model (add cryo, high‑dominance & missingness terms)
- New variance components:
  - var_cryo_all_zero = κ_cryo_zero * I(cryo_all_zero_flag) * novelty_scale
  - var_missingness = κ_miss * missingness_count
  - var_sign_inconsistency = κ_sign * (1 − dominance_sign_consistency_score)
  - var_dom_channel = κ_dom[c] * top1_share * novelty_scale
  - var_high_spend = κ_high_spend * log1p(top1_spend) * I(top1_spend ≥ TOP1_SPEND_HIGH)
  - var_cohort_uncertainty = κ_cohort * (1 − cohort_transport_consistency_score)
- Combine:
  - var_combined = var_base + var_dispersion + var_cryo_all_zero + var_missingness + var_sign_inconsistency + var_dom_channel + var_high_spend + var_cohort_uncertainty
  - se_combined = sqrt(max(var_combined, se_floor(context)^2))
- Start κs (sweepable):
  - κ_cryo_zero = 0.16; κ_dom baseline = 0.10; κ_dom_foodcourt = 0.14; κ_high_spend = 0.12; κ_miss = 0.06; κ_sign = 0.08; κ_cohort = 0.05; κ_dispersion = 0.02
- SE floors:
  - cryo_all_zero (n==1): se_floor ≥ 0.25–0.40 until N_slice ≥ N_min_cryo
  - top1_dom_small_slice (n==1): se_floor ≥ 0.20–0.30
  - stable slices: 0.06–0.10

E. Decision‑gating (pattern‑aware + batch/cohort aware)
- Fragile_flag (v6):
  - cryo_all_zero_flag OR top1_dom_flag OR high_spend_outlier_flag OR all_zero_flag OR imputed_zero_flag OR missingness_count ≥ 2 OR feature_dom_fraction ≥ 0.60 OR dominance_sign_consistency_score < 0.7 OR in_batch_cohort_contradiction_flag
- Batch/cohort checks:
  - batch_frac_fragile = (#fragile_records_in_batch) / batch_size
  - If batch_frac_fragile ≥ BATCH_FRAGILE_THRESHOLD → hold auto‑decisions for full batch (route to priority_audit) or queue for reviewed shadow‑predict.
  - If two or more records in same booking/cabin have contradictory predictions → hold bucket for priority audit.
- Gating pseudocode (ready to plug in):
  - Input: record r, batch B, cohort_id (optional)
  - fragile_flag = (cryo_all_zero_flag) OR (top1_share >= 0.60) OR (top1_spend >= 400) OR (all_zero_flag) OR (imputed_zero_flag) OR (missingness_count >= 2) OR (feature_dom_fraction >= 0.60) OR (dominance_sign_consistency_score < 0.7)
  - batch_frac_fragile = count_fragile(B)/|B|
  - if n_batch == 1 and fragile_flag:
      if cryo_all_zero_flag:
         require: pooled_prior_tau >= Z_high_cryo AND N_slice_cryo >= N_min_cryo AND GLM_fallback_agrees AND ensemble_agreement >= A_high AND se_combined <= SE_accept_cryo AND (p90 − p10) <= QW_accept_cryo
         else: route -> priority_audit
      else if top1_share >= 0.90 or high_spend_outlier_flag:
         route -> priority_audit
      else:
         allow_auto = (slice_context_score >= Z_high) AND (N_slice_for_context >= N_min_slice_for_slice_type) AND (GLM_fallback_agrees) AND (ensemble_agreement >= A_high) AND (se_combined <= SE_accept_for_slice_type) AND ((p90 − p10) <= QW_accept_for_slice_type) AND (dominance_sign_consistency_score >= SIGN_CONSIST_MIN)
         if not allow_auto:
             route -> priority_audit
  - if batch_frac_fragile >= BATCH_FRAGILE_THRESHOLD:
      hold_batch_auto_decisions -> priority_audit
  - if in_batch_cohort_contradiction_flag:
      hold_cohort -> priority_audit
- Example thresholds (starting):
  - N_min_cryo = 50
  - Z_high_cryo = pooled_prior_tau ≥ 0.90
  - SE_accept_cryo = 0.06 (only if N_slice_cryo ≥ N_min_cryo and pooled_prior_tau ≥ Z_high_cryo)
  - BATCH_FRAGILE_THRESHOLD = 0.05 (5%)
  - A_high (ensemble agreement) = 0.995
  - SIGN_CONSIST_MIN = 0.70

F. Calibrator & GLM_fallback retrain plan (cryo, dom, high‑spend focused)
- Calibrator:
  - Output p10/p50/p90 and sd using conformalized quantile regression or quantile pinball + heteroskedastic variance head.
  - Inputs: raw_logit, CryoSleep, all_zero_flag, imputed_zero_flag, top1_channel, top1_spend, top1_share, feature_dom_fraction, dominance_sign_consistency_score, missingness_count, spend_entropy_norm, cohort features, cohort_transport_consistency_score.
  - Loss: quantile pinball + ECE penalty + Brier; upweight cryo_all_zero, dom_high, high_spend_outliers, cohort_contradictions by ×5–10.
- GLM_fallback:
  - Interpretable regularized logistic (ElasticNet) with enforced per‑feature logit caps and interactions (CryoSleep×HomePlanet, CryoSleep×all_zero, top1_channel×top1_share, top1_spend).
  - GLM_fallback_agrees = |p_model − p_glm| ≤ δ (δ sweep 0.05–0.10 by slice)
  - GLM fallback used both as sanity check and as fallback prediction if model confidence is not usable.
- Training & validation:
  - Data window: rolling last 18–36 months; enforce stratified CV such that small slices (cryo_all_zero, dom_high, high_spend) appear in all folds.
  - Upweight schedule: cryo_all_zero ×10, top1_dom & high_spend ×5, cohort_contradictions ×10.
  - Shadow‑run: 14–28 days with gating active (no auto‑accepts for canaries).
- Acceptance criteria:
  - cryo_all_zero FN rate ↓ ≥ 40–60% in shadow run,
  - top1_dom/high_spend false positives ↓ ≥ 40–60%,
  - cohort contradictions reduced to < baseline ×0.5,
  - Global ECE not worsened by >0.5% absolute.

G. Monitoring, metrics & alerts (batch‑focused)
- Dashboards & slice metrics:
  - ECE, Brier, FP, FN, contradiction_count, n==1_auto_accept_rate, batch_frac_fragile, canary_auto_accepts, cryo_all_zero_false_negative_rate, top1_dom_false_positive_rate_by_channel, high_spend_FP_rate
- New batch KPIs:
  - Batch_auto_decision_rate, Batch_frac_fragile, Batch_provenance_consistency_rate, Cohort_contradiction_rate, Top1_dom_FN/FP_by_channel
- Alerts:
  - any canary auto‑accepted → immediate hold + page ML/Ops
  - cryo_all_zero FN rate > baseline + X% in 24h → hold auto‑accepts + page
  - top1_dom/high_spend FP rate > baseline + X% → page
  - batch_frac_fragile ≥ BATCH_FRAGILE_THRESHOLD → hold batch auto‑decisions & notify
  - any same‑cohort contradictory auto‑accept → page
- Canary list (initial): 0167_01 (all_zero_cryo), 0167_02 (RoomService high_spend_dom), 0164_01 (FoodCourt dom), 0160_01 (RoomService outlier), 0163_01 (all_zero + CryoSleep legacy), 0152_01, 0151_01, 0144_01, 0148_01, 0149_01.

H. CI unit tests & validation (cover cryo_all_zero, dom_high, cohort)
- Tests:
  - cryo_all_zero computed identically across scorer/calibrator/gate (same provenance).
  - se_combined increases when cryo_all_zero True and/or dominance_sign_consistency_score < 0.7.
  - calibrator widens p10/p90 for cryo_all_zero and sign_inconsistency records.
  - pooled‑prior blending uses per‑slice N0 (N0_cryo_all_zero respected).
  - per‑feature logit cap enforced (test extremes, ensure CryoSleep and RoomService caps applied).
  - batch_frac_fragile ≥ threshold disables auto‑decisions for entire batch.
  - cohort contradiction detection: if two same‑cohort records produce opposite auto‑decisions, both are held.
  - Canaries: 0167_01 and 0167_02 must not be auto‑accepted in unit test harness with gating active.
- Shadow‑run acceptance:
  - cryo_all_zero FN reduction target met,
  - top1_dom/high_spend FP reduction target met,
  - no canary auto‑accepts.

I. Operational actions (0–72 hours) — precise timeline
1) Immediate (0–6h)
   - Deploy n==1 gating patch (block auto‑decisions for fragile_flag). Add 0167_01 and 0167_02 to canary list and block them.
   - Persist provenance fields: raw spends, imputation flags, CryoSleep, per‑feature contributions, pooled_prior_snapshot_id, cohort_id/cabin.
   - Escalate: any cryo_all_zero or high_spend_dom auto‑accept → priority_audit page.
2) Short‑term (6–24h)
   - Expose var_cryo_all_zero, var_high_spend, var_missingness, var_feature_dom, var_dispersion, se_combined in scoring output.
   - Implement temporary per‑feature logit caps (2.5 for spend features, 2.0–2.5 for CryoSleep) and sign‑consistency downweight.
   - Implement batch‑level check to pause auto‑decisions if batch_frac_fragile ≥ 5% and cohort contradiction detection.
   - Instrument dashboards for cryo_all_zero_FN_rate, top1_dom_FP_rate_by_channel, cohort_contradiction_rate, and set alerts.
3) Mid‑term (24–72h)
   - Retrain calibrator & GLM_fallback using updated inputs, upweight contradictions; run 14–28 day shadow‑run with gating active.
   - Publish pooled‑prior snapshots for cryo_all_zero and dom_high slices.
   - Launch dashboards & alerts, seed active‑label queue with cryo_all_zero & high_spend contradictions for rapid labelling.
   - Run regression tests to ensure no global ECE regressions.

J. Per‑record provenance to log (required & extended)
- Raw channels: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck
- sum_spend (raw & log1p), sum_spend_bucket
- top1_channel, top1_spend, top1_share, top2_channel, top2_spend
- all_zero_flag, cryo_all_zero_flag, imputed_zero_flag, concentration_by_channel_flag
- spend_entropy_norm, num_nonzero_channels, missingness_count, missingness_profile
- feature_dom_fraction, per_feature_logit_contributions (map), dominance_sign_consistency_score, novelty_score, all_zero_context_score
- cohort_id/cabin_group_id, cohort_transport_consistency_score, in_batch_cohort_contradiction_flag
- pooled_prior_snapshot_id, μ_slice, τ_slice_blend
- var_cryo_all_zero, var_missingness, var_feature_dom, var_dispersion, var_high_spend, var_sign_inconsistency, se_combined
- GLM_fallback_probs, GLM_fallback_agreement_flag
- ensemble_probs, ensemble_agreement
- p10/p50/p90, p_final_sd, quantile_width
- gating_reasons, routing_decision (auto/priority_audit)
- scorer_version, calibrator_version, provenance_hash

K. Initial hyperparameters (start values; sweepable)
- N0_cryo_all_zero = 150
- TOP1_DOM_THRESHOLD = 0.60
- TOP1_SPEND_HIGH = 400
- BATCH_FRAGILE_THRESHOLD = 0.05 (5%)
- N_min_cryo = 50; N_min_slice = 50 (dom_high), 25 (other fragiles)
- Z_high (pooled_prior_confidence) = 0.90 (cryo_all_zero)
- A_high (ensemble agreement) = 0.995
- SE_accept_general = 0.06; SE_accept_cryo only if N_slice_cryo ≥ N_min_cryo and pooled_prior τ ≥ 0.90
- QW_accept_cryo (p90−p10) = 0.12
- CAP_PER_FEATURE_LOGIT = 2.5 (spend features), 2.0–2.5 (CryoSleep)
- κ_cryo_zero = 0.16; κ_dom baseline = 0.10; κ_dom_foodcourt = 0.14; κ_miss = 0.06; κ_sign = 0.08; κ_high_spend = 0.12; κ_cohort = 0.05

L. CI canaries & expected behavior
- 0167_01 (all spends = 0, CryoSleep = True):
  - Expected: route -> priority_audit (immediate escalation) unless (N_slice_cryo_all_zero ≥ N_min_cryo AND pooled_prior_tau ≥ 0.90 AND GLM_fallback_agrees AND se_combined ≤ 0.06 AND (p90 − p10) ≤ QW_accept_cryo).
- 0167_02 (RoomService = 1365, other spends low):
  - Expected: route -> priority_audit (dominance-driven decision requires cohort/context/pooled-prior backing). Only auto‑accept if cohort_transport_consistency_score high AND pooled_prior backing for this channel/demographic AND GLM_fallback_agrees AND se_combined small.
- Unit tests must assert these behaviors in harness with gating active.

Why this will reduce batch errors (short)
- Fragile gating prevents overconfident auto‑decisions on n==1 low‑context slices (cryo_all_zero, dom_high, high_spend).
- Cryo/all_zero and top1_dom pooled priors with larger N0 prevent single records from overturning priors inappropriately.
- New variance terms (var_cryo_all_zero, var_high_spend, var_sign) inflate calibrated uncertainty for brittle slices; gate requires multi‑model consensus or cohort backing before auto‑deciding.
- Per‑feature logit caps and sign‑consistency downweighting stop single features from flipping predictions when historically unstable.
- Cohort/batch checks detect contradictory in‑batch predictions (same Cabin/Booking) and hold them.
- Standardized transforms + persisted provenance remove mismatch bugs across scorer/calibrator/gate.
- Retraining with upweighted contradictions corrects directionality and reduces similar brittle future errors.

Immediate one‑line corrective action
- Deploy n==1 gating: route any record with cryo_all_zero_flag OR top1_share ≥ 0.60 OR top1_spend ≥ 400 OR all_zero_flag OR imputed_zero_flag OR missingness_count ≥ 2 to priority_audit (immediately escalate cryo_all_zero and top1_share ≥ 0.90); add 0167_01 and 0167_02 to the canary list.

Concrete gating pseudocode (batch + cohort aware)
- Input: batch B, for each record r in B:
    read provenance fields: CryoSleep, all_zero_flag, cryo_all_zero_flag, top1_share, top1_spend, feature_dom_fraction, dominance_sign_consistency_score, missingness_count, imputed_zero_flag, pooled_prior_tau, N_slice_cryo, cohort_id
- count_fragile = sum over B of fragile_flag(r)
- batch_frac_fragile = count_fragile / len(B)
- for each r:
    fragile_flag = (cryo_all_zero_flag) OR (top1_share >= 0.60) OR (top1_spend >= 400) OR (all_zero_flag) OR (imputed_zero_flag) OR (missingness_count >= 2) OR (feature_dom_fraction >= 0.60) OR (dominance_sign_consistency_score < 0.7)
    if batch_frac_fragile >= BATCH_FRAGILE_THRESHOLD:
        route r -> priority_audit
        continue
    if n_batch == 1 and fragile_flag:
        if cryo_all_zero_flag:
            if pooled_prior_tau >= Z_high_cryo AND N_slice_cryo >= N_min_cryo AND GLM_fallback_agrees AND ensemble_agreement >= A_high AND se_combined <= SE_accept_cryo AND (p90 - p10) <= QW_accept_cryo:
                allow_auto = True
            else:
                route r -> priority_audit
                continue
        else if top1_share >= 0.90 or high_spend_outlier_flag:
            route r -> priority_audit
            continue
        else:
            allow_auto = (slice_context_score >= Z_high) AND (N_slice_for_context >= N_min_slice) AND (GLM_fallback_agrees) AND (ensemble_agreement >= A_high) AND (se_combined <= SE_accept_for_slice_type) AND ((p90 - p10) <= QW_accept_for_slice_type) AND (dominance_sign_consistency_score >= SIGN_CONSIST_MIN)
            if not allow_auto:
                route r -> priority_audit
                continue
    # cohort contradiction check
    if cohort_id present:
        if exists r2 in B with same cohort_id and sign(p_final_r) != sign(p_final_r2):
            mark cohort contradiction; route all cohort members -> priority_audit

Next steps / offer
- I recommend immediate rollout of the stopgap gating patch (option 1) and simultaneously preparing the full retrain + shadow‑run (option 2).
  1) Minimal gating patch (0–6h): exact pseudocode, unit tests (including canaries 0167_01 & 0167_02), and deploy checklist — ready in 1–3 hours.
  2) Full retrain & deployment plan (24–72h): dataset selection, upweight schedule for contradictions, CV folds preserving small slices, hyperparameter sweep plan, shadow‑run dashboard definitions, and rollout checklist.
- Which do you want first? I can now produce:
  - (A) Immediate gating patch: code‑style pseudocode, unit tests for canaries, and a deploy checklist; or
  - (B) Full retrain recipe: training dataset, CV plan, upweight schedule, hyperparameter sweep commands, and shadow‑run metrics dashboard definitions.

If you want the stopgap deployed this hour I will output the exact gating patch (pseudocode + unit tests) and a tight deploy checklist now.

============================================================