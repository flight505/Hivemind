PREDICTIVE METRICS - ITERATION 130
============================================================

Executive summary — immediate takeaways & top priorities (0–72h)
- What happened (short):
  - A 1‑record batch (Passenger 0170_01) with concentrated spends (VRDeck=567, Spa=221, others zero; sum_spend=788, top1_share≈0.72, top1_spend=567) was auto‑predicted Transported (false positive). This is the same brittle pattern as prior failures: single‑feature dominance + tiny‑batch allowed an overconfident decision.
- Immediate root causes (short):
  - n==1 auto‑decision logic is too permissive for fragile records,
  - pooled priors not stratified enough for top1_dom/top‑channel slices,
  - calibrator under‑estimates uncertainty for novelty / high‑dominance records,
  - no total‑spend / top‑k logit caps so multiple spend features (or one very large) can overwhelm priors,
  - no novelty/cohort backing requirement for single‑record high‑spend cases (no cohort smoothing or cross‑passenger consistency checks).
- Immediate stopgap (0–6h):
  - Block n==1 auto‑decisions for fragile_flag; fragile_flag must include top1_dom_flag (top1_share ≥ 0.60) and top1_spend ≥ 400 and/or imputed/missingness indicators. Add 0170_01 to canary list and route to priority_audit. Persist raw spends, imputation provenance and per‑feature logits.

Concise answers to your six questions (batch accuracy focus)
1) What specific patterns caused this error?
- High single‑channel dominance (VRDeck top1_share ≈ 0.72 and top1_spend=567) in a 1‑record batch. The scorer produced strong spend‑feature logits; calibrator under‑inflated uncertainty; gating allowed auto‑accept without cohort/pooled‑prior support.

2) How should decision rules be modified to prevent recurrence?
- Disallow n==1 auto‑decisions when fragile flags present (top1_dom, high_top1_spend, cryo_all_zero, imputed/missingness). Require: pooled‑prior backing (τ high and N_slice ≥ threshold) + GLM_fallback agreement + ensemble agreement + small quantile width + se_combined below slice‑specific floor. Otherwise route to priority_audit.

3) What new insights about transport patterns?
- High spend in VRDeck/Spa is a noisy, context‑dependent signal — not a universal indicator of Transported. The sign and magnitude of spend channels vary by demographic/booking cohort. Multi‑channel patterns (which channels are non‑zero) and cohort information are as important as raw magnitude.

4) How should confidence levels be recalibrated?
- Use a heteroskedastic, slice‑aware calibrator that produces p10/p50/p90 and sd. Inflate uncertainty for top1_dom, high_top1_spend, low‑entropy spend patterns, and n==1 slices via var_dom_channel, var_high_spend, var_novelty and se_floor. Consider conformalized quantile regression + variance head.

5) What adjustments are needed for batch consistency?
- Persist transforms & provenance across scorer→calibrator→gate. Add batch_frac_fragile checks (if fraction of fragile records in batch ≥ threshold, hold auto‑decisions for entire batch). Add cohort contradiction detection (same booking/cabin conflicting predictions → hold them).

6) How can metrics be improved to handle edge cases?
- Add top1_dom/top‑channel pooled priors (with larger N0), var_dom & var_high_spend variance terms, total‑spend logit caps and per‑channel caps, top‑k dominance metrics, novelty scores (Mahalanobis/kNN) and upweight these edge cases during retraining.

Complete updated predictive metrics report — actionable components (optimized for batch accuracy)

A. Feature engineering updates (v→v+1)
- Spend aggregates:
  - sum_spend = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck
  - sum_spend_log = log1p(sum_spend)
  - sum_spend_bucket = [0,50,200,400,600,800,2000+]
- Zero / imputation / missingness:
  - all_zero_flag = (all five spends == 0)
  - cryo_all_zero_flag = (CryoSleep == True AND all_zero_flag)
  - imputed_zero_flag = any spend value was imputed as 0 (record imputation provenance)
  - missingness_count, missingness_profile (which channels were missing vs true zero)
- Dominance & novelty:
  - top1_channel, top1_spend, top1_share = top1_spend / max(sum_spend, 1e-6)
  - top2_spend, top2_share, topk_share = (top1_spend + top2_spend) / sum_spend
  - top1_dom_flag = top1_share ≥ TOP1_DOM_THRESHOLD (start 0.60)
  - topk_dom_flag = topk_share ≥ TOPK_DOM_THRESHOLD (e.g., top2_share_sum ≥ 0.85 → special handling)
  - spend_entropy_norm, num_nonzero_channels
  - feature_dom_fraction = per‑feature logit contribution / sum_abs_logit_contrib
  - dominance_sign_consistency_score: historical fraction with same sign for this channel in matching buckets
  - novelty_distance: Mahalanobis/kNN distance of spend pattern to historical centroids; if large → novelty_flag
- Cohort / inter‑record:
  - booking_id / cabin_group_id
  - cohort_transport_consistency_score = fraction transported historically for that booking/cabin
  - in_batch_cohort_contradiction_flag
- Interactions:
  - CryoSleep×all_zero_flag, CryoSleep×HomePlanet, top1_channel×top1_share, top1_share×Age_bucket, novelty_distance×top1_channel

B. Pooled priors (cryo‑aware + channel/demographic/family stratified)
- Stratify priors by (CryoSleep, all_zero_flag, top1_channel, top1_share_bucket, HomePlanet, Destination, Age_bucket). Persist snapshots per deploy.
- Blend with τ_slice = N_slice / (N_slice + N0_slice).
- Use larger N0 for fragile slices:
  - N0_cryo_all_zero = 150
  - N0_top1_dom baseline = 150; increase per high‑variance channel (VRDeck, Spa) to 200.
- For multi‑channel novelty patterns (unseen top1/top2 combos) use larger N0 or fall back to coarser priors.

C. Per‑feature logit caps & sign‑consistency downweighting
- Enforce:
  - CAP_PER_FEATURE_LOGIT defaults: spend features 2.5; VRDeck & Spa start at 2.0 (sweepable); CryoSleep 2.0.
  - CAP_TOTAL_SPEND_LOGIT = 3.0 (sum of spend feature logits clipped to this).
- If dominance_sign_consistency_score < SIGN_CONSIST_MIN (0.70), scale that feature’s contribution by scale = max(0.3, dominance_sign_consistency_score).
- If novelty_distance > NOVELTY_THRESHOLD: downward scale spend logits by 0.5–0.8.
- If imputed_zero_flag True: downweight spend logits (×0.6–0.8).
- Allow modest relaxation if cohort_transport_consistency_score ≥ 0.90 and cohort_size ≥ COHORT_MIN (e.g., 3).

D. Variance / SE model (add domain & novelty terms)
- New variance components (add to var_base):
  - var_dom_channel = κ_dom[c] * top1_share * novelty_scale (higher κ for VRDeck/Spa)
  - var_topk = κ_topk * (1 − (top1_share − top2_share)) to capture ambiguous multi‑dominance
  - var_high_spend = κ_high_spend * log1p(top1_spend) * I(top1_spend ≥ TOP1_SPEND_HIGH)
  - var_novelty = κ_novel * novelty_distance_norm
  - var_missingness = κ_miss * missingness_count
  - var_sign_inconsistency = κ_sign * (1 − dominance_sign_consistency_score)
  - var_cohort_uncertainty = κ_cohort * (1 − cohort_transport_consistency_score)
- Combined:
  - var_combined = var_base + var_dispersion + sum(new_var_components)
  - se_combined = sqrt(max(var_combined, se_floor(context)^2))
- Starting κs (sweepable; conservative starts):
  - κ_dom baseline = 0.10; κ_dom_vrdeck = 0.18; κ_dom_spa = 0.16
  - κ_topk = 0.08; κ_high_spend = 0.12; κ_novel = 0.14; κ_miss = 0.06; κ_sign = 0.08; κ_cohort = 0.05; κ_dispersion = 0.02
- SE floors:
  - n==1 fragile (top1_dom/high_spend/novel): se_floor = 0.25–0.40 until N_slice ≥ N_min
  - stable slices: se_floor = 0.06–0.10

E. Decision‑gating (pattern‑aware + batch/cohort aware)
- Fragile_flag (v7):
  - cryo_all_zero_flag OR top1_dom_flag (top1_share ≥ 0.60) OR high_spend_outlier_flag (top1_spend ≥ 400) OR novelty_flag OR imputed_zero_flag OR missingness_count ≥ 2 OR feature_dom_fraction ≥ 0.60 OR dominance_sign_consistency_score < 0.7 OR in_batch_cohort_contradiction_flag
- Batch/cohort checks:
  - batch_frac_fragile = (#fragile_records_in_batch) / batch_size
  - If batch_frac_fragile ≥ BATCH_FRAGILE_THRESHOLD (start 0.05) → hold auto‑decisions for full batch → priority_audit / shadow
  - If two or more same‑cohort records have contradictory predicted signs → hold cohort
- Default gating rule for n_batch==1:
  - If fragile_flag: require all of:
      - pooled_prior_tau ≥ Z_high_slice (e.g., 0.90) AND N_slice ≥ N_min_slice (e.g., 50 for top1_dom) AND
      - GLM_fallback_agrees (|p_model − p_glm| ≤ δ_slice) AND
      - ensemble_agreement ≥ A_high (0.995) AND
      - se_combined ≤ SE_accept_slice AND (p90 − p10) ≤ QW_accept_slice
    else route -> priority_audit
- For mixed batches: if bulk auto‑decisions but batch_frac_fragile ≥ threshold, hold entire batch.
- Example thresholds (initial):
  - N_min_top1_dom = 50; N_min_cryo = 50
  - Z_high_slice = 0.90
  - A_high = 0.995
  - SE_accept_general = 0.06 (only when N_slice conditions met)
  - QW_accept_cryo = 0.12
  - SIGN_CONSIST_MIN = 0.70

F. Calibrator & GLM_fallback retrain plan (cryo, dom, high‑spend, novelty focused)
- Calibrator:
  - Output p10/p50/p90 and sd using conformalized quantile regression (CQR) or quantile pinball + heteroskedastic variance head.
  - Inputs: raw_logit, CryoSleep, all_zero_flag, imputed_zero_flag, top1_channel, top1_spend, top1_share, top2_share, feature_dom_fraction, dominance_sign_consistency_score, missingness_count, novelty_distance, cohort features.
  - Loss: quantile pinball + ECE penalty + Brier; upweight fragile slices ×5–10.
- GLM_fallback:
  - Interpretable ElasticNet logistic with enforced per‑feature logit caps and interactions (CryoSleep×all_zero, top1_channel×top1_share, top1_spend). GLM used for sanity checks and fallback.
  - GLM_fallback_agrees = |p_model − p_glm| ≤ δ (start δ=0.06 for fragile slices, 0.10 general).
- Training:
  - Window: rolling 18–36 months; ensure stratified CV where fragile slices are present in each fold.
  - Upweight schedule: cryo_all_zero ×10, top1_dom & high_spend & novelty ×5–10, cohort_contradictions ×10.
  - Shadow‑run: 14–28 days with gating active (no auto‑accepts for canaries).
- Acceptance criteria:
  - top1_dom FP rate ↓ ≥ 40–60% in shadow run,
  - cryo_all_zero FN rate ↓ similarly,
  - cohort contradictions reduced by ≥50%,
  - Global ECE no worse by >0.5% absolute.

G. Monitoring, metrics & alerts (batch‑focused)
- Dashboards & slice metrics:
  - ECE, Brier, FP, FN, contradiction_count, n==1_auto_accept_rate, batch_frac_fragile, canary_auto_accepts, top1_dom_FP_rate_by_channel, novelty_FP_rate
- Batch KPIs:
  - Batch_auto_decision_rate, Batch_frac_fragile, Batch_provenance_consistency_rate, Cohort_contradiction_rate
- Alerts:
  - any canary auto‑accepted → immediate hold + page ML/Ops
  - top1_dom_FP_rate_by_channel increase > baseline + X% → page
  - batch_frac_fragile ≥ BATCH_FRAGILE_THRESHOLD → hold batch auto‑decisions & notify
  - same‑cohort contradictory auto‑accept → page
- Initial canary list add: 0170_01 (VRDeck+Spa dom), 0167_02, 0167_01, others.

H. CI unit tests & validation (cover top1_dom, novelty, cohort)
- Tests:
  - top1_dom (various channels) computed identically across scorer/calibrator/gate,
  - se_combined increases for top1_dom & novelty_flag,
  - calibrator widens p10/p90 for novelty/high_dominance,
  - pooled‑prior blending respects N0_top1_dom,
  - per‑feature and total spend logit caps enforced,
  - batch_frac_fragile ≥ threshold disables auto‑decisions,
  - cohort contradiction detection holds cohorts,
  - canaries (including 0170_01, 0167_01, 0167_02) are not auto‑accepted during gating tests.
- Shadow run acceptance targets included.

I. Operational actions (0–72 hours) — precise timeline
1) Immediate (0–6h)
   - Deploy n==1 gating patch: block auto‑decisions for fragile_flag; add 0170_01 to canary list and block it.
   - Persist provenance fields: raw spends (per channel), imputation flags, per‑feature logit contributions, pooled_prior_snapshot_id, cohort_id.
   - Enforce temporary per‑feature logit caps (spend cap 2.5; VRDeck/ Spa 2.0) and CAP_TOTAL_SPEND_LOGIT = 3.0.
   - Escalate: any top1_dom/high_spend auto‑accept → priority_audit page.
2) Short‑term (6–24h)
   - Expose var_dom_channel, var_high_spend, var_novelty, se_combined in scoring output.
   - Implement batch‑level check to pause auto‑decisions if batch_frac_fragile ≥ 5% and cohort contradiction detection.
   - Instrument dashboards for top1_dom_FP_rate_by_channel and novelty_FP_rate; set alerts.
3) Mid‑term (24–72h)
   - Retrain calibrator & GLM_fallback with updated inputs and upweight schedule; run 14–28 day shadow‑run with gating active.
   - Publish pooled‑prior snapshots for top1_dom/channel slices.
   - Seed active label queue with top1_dom & novelty cases for rapid labeling & feedback loop.
   - Run CI/regression tests to ensure no global ECE regression.

J. Per‑record provenance to log (required & extended)
- Raw channels: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck (raw & imputation provenance)
- sum_spend, sum_spend_log, sum_spend_bucket
- top1_channel, top1_spend, top1_share, top2_channel, top2_spend, top2_share
- all_zero_flag, cryo_all_zero_flag, imputed_zero_flag, missingness_count, num_nonzero_channels
- spend_entropy_norm, feature_dom_fraction, per_feature_logit_contributions (map)
- dominance_sign_consistency_score, novelty_distance, all_zero_context_score
- cohort_id/cabin_group_id, cohort_transport_consistency_score, in_batch_cohort_contradiction_flag
- pooled_prior_snapshot_id, μ_slice, τ_slice_blend
- var_dom_channel, var_high_spend, var_novelty, var_missingness, var_sign_inconsistency, var_combined, se_combined
- GLM_fallback_probs, GLM_fallback_agreement_flag
- ensemble_probs, ensemble_agreement
- p10/p50/p90, p_final_sd, quantile_width
- gating_reasons, routing_decision (auto/priority_audit)
- scorer_version, calibrator_version, provenance_hash

K. Initial hyperparameters (start values; sweepable)
- TOP1_DOM_THRESHOLD = 0.60
- TOP1_SPEND_HIGH = 400
- CAP_PER_FEATURE_LOGIT: spend features = 2.5; VRDeck/Spa = 2.0
- CAP_TOTAL_SPEND_LOGIT = 3.0
- BATCH_FRAGILE_THRESHOLD = 0.05 (5%)
- N0_cryo_all_zero = 150; N0_top1_dom = 150–200
- N_min_top1_dom = 50; N_min_cryo = 50
- Z_high_slice = 0.90; A_high = 0.995
- SE_accept_general = 0.06; se_floor_n1_fragile = 0.25–0.40
- κ_dom_vrdeck = 0.18; κ_dom_spa = 0.16; κ_dom_baseline = 0.10; κ_novel = 0.14; κ_high_spend = 0.12; κ_miss = 0.06

L. CI canaries & expected behavior (add 0170_01)
- 0170_01 (VRDeck=567, Spa=221, others 0):
  - Expected: route -> priority_audit (dominance + high_spend in n==1 requires pooled_prior/GLM/ensemble backing). Must not be auto‑accepted in unit tests/gating.
- 0167_01 (all_zero + CryoSleep True): route -> priority_audit unless slice N and τ high & GLM/ensemble agree.
- 0167_02 (RoomService dom): route -> priority_audit.
- Unit tests must assert these behaviors.

Why this will reduce batch errors (short)
- Fragile gating and stricter n==1 rules prevent overconfident single‑record flips.
- Per‑feature & total spend logit caps stop multiple high spend features from cumulatively overwhelming priors.
- Pooled priors stratified by top1_channel/top1_share and larger N0 for fragile slices stop small‑N overturns.
- New variance terms and se_floor widen calibrated uncertainty for brittle slices; gating then requires multi‑model/cohort confirmation.
- Cohort and batch consistency checks catch contradictory in‑batch predictions.
- Retraining with upweighted edge cases corrects directionality over time.

Immediate one‑line corrective action
- Deploy gating patch: route any n==1 record with top1_share ≥ 0.60 OR top1_spend ≥ 400 OR cryo_all_zero_flag OR imputed_zero_flag OR missingness_count ≥ 2 to priority_audit; add 0170_01 to canary list.

Gating pseudocode (concise)
- For each batch B:
  - compute batch_frac_fragile = count(r in B where fragile_flag)/|B|
  - for each record r:
      fragile_flag = cryo_all_zero_flag OR top1_share ≥ 0.60 OR top1_spend ≥ 400 OR novelty_flag OR imputed_zero_flag OR missingness_count ≥ 2
      if batch_frac_fragile ≥ 0.05: route r -> priority_audit; continue
      if n_batch == 1 and fragile_flag: route r -> priority_audit (unless pooled_prior_tau ≥ 0.90 & N_slice ≥ 50 & GLM_agrees & ensemble_agreement ≥ 0.995 & se_combined ≤ 0.06 & (p90 − p10) ≤ 0.12)
      if cohort_id present and exists conflicting sign predictions: route all cohort members -> priority_audit

Next steps / offer
- I recommend immediate rollout of the stopgap gating patch now (0–6h) and running a parallel plan to retrain calibrator + GLM_fallback and shadow‑run (24–72h).
  - Option A (now, 0–3h): I will output the exact gating patch (ready‑to‑implement pseudocode), unit tests (including canary 0170_01), and a tight deploy checklist.
  - Option B (24–72h): I will produce the full retrain recipe, upweight schedule, CV plan, hyperparameter sweep definitions, and shadow‑run dashboard spec.
Which do you want first? If you want the stopgap deployed this hour I will produce the gating patch + unit tests + deploy checklist immediately.

============================================================