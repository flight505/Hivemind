PREDICTIVE METRICS - ITERATION 122
============================================================

Executive summary — immediate takeaways & top priorities (0–72h)
- What happened (short): Two brittle single-record slices surfaced:
  - Dominant-channel concentration: 0160_01 (Gory Atkinney) — RoomService = 4,119, top1_share ≈ 0.985 → model predicted Transported (false positive) but actual = Not‑transported.
  - All-zero + CryoSleep contradiction: 0163_01 (Kabiton Hetforhaft) — all spend = 0 & CryoSleep = True → model predicted Not‑transported (false negative) but actual = Transported.
  These are recurring brittle modes (feature_dom / top1_dom and cryo_all_zero / all_zero) that the pipeline currently treats as low‑uncertainty and therefore allows overconfident auto-decisions.
- Immediate root causes (short):
  - permissive n==1 auto-decision logic (single-record batches allowed to auto-decide),
  - pooled priors not stratified for dominant-channel concentration and cryo/all-zero contexts,
  - calibrator under‑estimates uncertainty for novel/low-context slices,
  - per-feature logit contributions are unbounded so a single feature can dominate the decision,
  - transform/provenance mismatches between scorer ↔ calibrator ↔ gate (same indicators computed differently),
  - no batch-level gating for concentration/fragile pattern prevalence.
- Immediate stopgap (0–6h): Block any n==1 auto-decision that meets fragile_flag (top1_share ≥ 0.60 OR top1_spend ≥ 400 OR cryo_all_zero_flag OR all_zero_flag OR missingness_count ≥ 2). Route those records to priority_audit and add these records (0160_01, 0163_01, 0152_01, etc.) to canary list. Persist provenance fields so calibrator and gate use identical inputs.

Concise answers to the six questions (focused on batch accuracy)
1) What specific patterns caused this error?
- Two brittle patterns:
  - top1_dom / feature_dom: single-channel extreme spend dominating the logit (e.g., RoomService 4,119). One feature overwhelms the logit and the calibrator did not inflate uncertainty.
  - all_zero + CryoSleep: zero-spend with CryoSleep can be label-contradictory; pooled priors treated this with insufficient nuance so the scorer favored the common class incorrectly.
  Also: n==1 auto-decisions and mismatched provenance allowed these high‑novelty records to be auto-accepted.

2) How should decision rules be modified to prevent recurrence?
- Treat top1_dom and cryo_all_zero as fragile. For n==1 & fragile_flag, require stricter gating (slice_context_score, N_slice, GLM_fallback agreement, ensemble_agreement, and tight se/quantile width). Otherwise route to priority_audit.
- If batch_frac_fragile ≥ 5% then hold auto-decisions for entire batch.

3) What new insights about transport patterns?
- High absolute spend concentrated in one channel is not uniformly predictive — it often signals novelty or data issues rather than a stable signal.
- CryoSleep with all-zero spends is a contextual contradiction: it interacts sign/directionally with destination/homeplanet/age and must be treated separately.
- Both patterns are low-context — single records or small slices — so uncertainty must be increased until more context is available.

4) How should confidence levels be recalibrated?
- Calibrator must emit p10/p50/p90 and sd. Add a dom-aware variance term (var_dom_high) and cryo/all-zero variance that inflates uncertainty for brittle slices.
- Use dynamic SE floors: 0.25–0.35 for fragiles; 0.06–0.10 for stable slices. Gate decisions on se_combined and p90−p10 width, not just p50.

5) What adjustments are needed for batch consistency?
- Persist and standardize transforms/provenance across scorer/calibrator/gate.
- Stratify pooled priors by top1_channel × top1_share_bucket × CryoSleep.
- Add per-feature logit caps and dominance-scaling to bound single-feature influence.
- Add batch-level checks and hold batch if fragiles exceed thresholds.

6) How can metrics be improved to handle edge cases?
- Add dominant-channel-specific pooled priors, var_dom_high, and upweight contradiction examples during retraining. Add specialized monitoring, canaries and unit tests for dom_high and cryo_all_zero slices.

Complete updated predictive metrics report — actionable components (optimized for batch accuracy)

A. Feature engineering updates (v→v+1)
- Aggregates:
  - sum_spend = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck (also log1p(sum_spend)).
  - sum_spend_bucket = [0,50,200,400,600,800,2000+].
- Dominance & novelty flags:
  - top1_channel, top1_spend, top1_share = top1_spend / max(sum_spend, ε).
  - top1_share_bucket = [0–0.3, 0.3–0.5, 0.5–0.7, 0.7–0.9, 0.9+].
  - top1_dom_flag = top1_share ≥ TOP1_DOM_THRESHOLD (start 0.60).
  - top1_spend_high_flag = top1_spend ≥ TOP1_SPEND_HIGH (start 400).
  - spend_entropy_norm = normalized Shannon entropy across channel spends.
  - num_nonzero_channels, missingness_count, missingness_profile.
  - feature_dom_fraction = |contribution_top1| / sum(|contributions_all|) computed from the model’s per-feature logit contributions (requires consistent provenance).
  - novelty_score = Mahalanobis or kNN distance to nearest historical centroid in context space (top1_share, top1_spend, spend_entropy, age, homeplanet, cryo).
- Interactions:
  - top1_channel × top1_share, top1_channel × sum_spend_bucket, top1_share × sum_spend, top1_channel × Age_bucket, CryoSleep × all_zero_flag.

B. Pooled priors (channel-aware + dom-aware + cryo-aware)
- Compute stratified priors μ_dom_channel_demo = P(transported | top1_channel=c, top1_share_bucket=b, CryoSleep=t, context dims).
- Blend using slice weight τ_slice = N_slice / (N_slice + N0_slice).
- Use larger N0 for fragile slices:
  - N0_dom_channel initial 75 (sweep 50–200).
  - N0_all_zero_cryo initial 100.

C. Per-feature logit caps & bounded dominance scaling
- Enforce per-feature logit contribution cap:
  - CAP_PER_FEATURE_LOGIT = 3.0 logits (initial).
- Compute feature_dom_fraction (requires stable per-feature provenance).
- If feature_dom_fraction > 0.60, scale top1 contribution:
  - scale = max(0.5, 1 − (feature_dom_fraction − 0.6)) — example; sweep for best function.
- Rationale: prevents single features from flipping an otherwise modest base logit.

D. Variance / SE model (add dom & cryo terms)
- New variance components (example formulas; tune κ’s):
  - var_dom_high = κ_dom * top1_share * novelty_scale * (1 + sqrt(num_imputed_features)).
  - var_all_zero_cryo = κ_zero_cryo * indicator(cryo_all_zero_flag) * novelty_scale.
  - var_missingness = κ_miss * missingness_count.
- Combine:
  - var_combined = var_base + var_dispersion + var_dom_high*(top1_dom_flag) + var_all_zero_cryo*(cryo_all_zero_flag) + var_missingness + ...
  - se_combined = sqrt(max(var_combined, se_floor(context)^2))
- Default κs (start; sweepable):
  - κ_dom = 0.10; κ_zero_cryo = 0.12; κ_miss = 0.05; κ_dispersion = 0.02.
- Dynamic SE floors:
  - fragiles (dom_high, cryo_all_zero): se_floor = 0.25–0.35
  - stable slices: se_floor = 0.06–0.10
  - For n==1 & top1_dom_flag: enforce se_floor ≥ 0.20 until N_slice ≥ N_min

E. Decision-gating (pattern-aware)
- Fragile_flag (v3):
  - top1_dom_flag OR top1_spend_high OR all_zero_flag OR cryo_all_zero_flag OR missingness_count ≥ 2 OR feature_dom_fraction ≥ 0.60.
- Gating pseudocode:
  - if n == 1 and fragile_flag:
      allow_auto_decision = (
        slice_context_score ≥ Z_high AND
        N_slice ≥ N_min_slice_for_slice_type AND
        GLM_fallback_agrees AND
        ensemble_agreement ≥ A_high AND
        se_combined ≤ SE_accept_for_slice_type AND
        (p90 − p10) ≤ QW_accept_for_slice_type
      )
      if not allow_auto_decision:
         route -> priority_audit
- Special-for-dom_high (example thresholds):
  - N_min_slice = 50; Z_high = 0.85; A_high = 0.995; SE_accept ≤ 0.06; QW_accept ≤ 0.12; require GLM_fallback_agrees
- Batch-level rule:
  - if batch_frac_fragile ≥ BATCH_FRAGILE_THRESHOLD (5%) then hold auto-decisions for entire batch and require human in the loop.

F. Calibrator & GLM_fallback retrain plan (dominant-channel & cryo interactions)
- Calibrator must output p10/p50/p90/sd; use quantile regression + uncertainty decomposition.
- Calibrator inputs: raw_logit, top1_channel, top1_share, top1_dom_flag, cryo_all_zero_flag, ensemble_agreement, spend_entropy_norm, feature_dom_fraction, missingness_count, context dims.
- Loss: quantile pinball + ECE penalty + Brier weight; upweight dom_high & cryo_all_zero contradictions ×5–10 initially.
- GLM_fallback:
  - Build interpretable GLM/regularized logistic with top1_channel×top1_share, top1_share×sum_spend, CryoSleep×top1_channel interactions.
  - Regularize and enforce per-feature logit caps in GLM as well.
- Training & validation:
  - Time window: rolling last 18–36 months; preserve small-slice examples with stratified CV.
  - Shadow-run: 14–28 days, while gating/stopgaps active; no auto-accepts for canaries.
- Acceptance criteria:
  - dom_high contradictions ↓ ≥ 40–60% (relative)
  - cryo_all_zero contradictions ↓ ≥ 40–60%
  - No canary auto-accepts in shadow-run
  - Global ECE not worsened by >0.5–1.0% absolute

G. Monitoring, metrics & alerts (batch-focused)
- Dashboards per-slice & global: ECE, Brier, FP, FN, contradiction_count, n==1_auto_accept_rate, batch_frac_fragile, canary_auto_accepts.
- New batch KPIs: Batch_auto_decision_rate, Batch_frac_fragile, Batch_provenance_consistency_rate.
- Alerts:
  - any canary auto-accepted → immediate hold + page ML/Ops
  - slice FP or FN >20% deviance from baseline (24h) → hold auto-accepts + page
  - batch_frac_fragile ≥ 5% → hold batch auto-decisions & notify
  - sudden jump in n==1_auto_accept_rate (>5% absolute in 24h) → notify
- Canary list to seed monitoring: 0160_01, 0163_01, 0152_01, 0151_01, 0144_01, 0148_01, 0149_01.

H. CI unit tests & validation (must include dom_high & cryo_all_zero)
- Tests:
  - top1_dom_flag computed consistently across scorer/calibrator/gate (identical provenance).
  - se_combined increases when top1_dom_flag True.
  - calibrator widens quantile spreads for dom_high & cryo_all_zero.
  - pooled-prior blending respects N0_dom_channel and N0_all_zero_cryo.
  - per-feature logit cap enforced (no single feature contribution > CAP_PER_FEATURE_LOGIT).
  - batch-level: if batch_frac_fragile ≥ threshold then auto-decisions disabled for batch.
  - canary test harness: canaries must not be auto-accepted in unit test harness.
- Shadow-run acceptance:
  - dom_high contradictions reduced by target percentage
  - cryo_all_zero contradictions reduced by target percentage
  - no canary auto-accepts

I. Operational actions (0–72 hours) — precise timeline
1) Immediate (0–6h)
   - Deploy n==1 gating patch: block auto-decisions for top1_share ≥ 0.60 OR top1_spend ≥ 400 OR cryo_all_zero_flag OR all_zero_flag OR missingness_count ≥ 2. Route to priority_audit.
   - Add canaries (0160_01, 0163_01, others) to canary list and block their auto-decisions.
   - Persist provenance fields (top1/top2/flags/var_terms/CryoSleep/ensemble_agreement/feature_contributions) in scoring logs so gate/calibrator see identical values.
   - Data validation: if any spend > 99.9 percentile (or > cap) mark anomalous and flag for audit.
2) Short-term (6–24h)
   - Expose var_dom_high, var_all_zero_cryo, var_all_zero, var_feature_dom, var_dispersion in provenance; compute se_combined in scoring output.
   - Implement temporary per-feature logit caps (3.0 logits).
   - Implement batch-level check to pause auto-decisions if batch_frac_fragile ≥ 5%.
   - Instrument dashboards for dom_high_by_ctx and cryo_all_zero_by_ctx and set alerts.
3) Mid-term (24–72h)
   - Retrain calibrator & GLM_fallback with top1_channel×top1_share and CryoSleep interactions, upweight contradictions; run 14–28 day shadow-run.
   - Publish updated pooled-prior snapshots (μ_dom_channel_demo, μ_all_zero_cryo).
   - Launch dashboards & alerts for targeted slices and canaries.
   - Seed active-label queue with dom_high and cryo_all_zero contradictions for rapid labeling.

J. Per-record provenance to log (required & extended)
- Raw channels: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck
- sum_spend (raw & log1p), sum_spend_bucket
- top1_channel, top1_spend, top1_share, top1_share_bucket, top2_channel, top2_spend, top2_share
- all_zero_flag, cryo_all_zero_flag, top1_dom_flag, concentration_by_channel_flag
- spend_entropy_norm, num_nonzero_channels, missingness_count, missingness_profile
- feature_dom_fraction, per_feature_logit_contributions (map), novelty_score
- top1_channel_context_score, dom_channel_context_score, all_zero_context_score, N_slice
- var_dom_high, var_all_zero, var_all_zero_cryo, var_feature_dom, var_dispersion, se_combined
- μ_dom_channel_demo, μ_all_zero_demo, τ_slice_blend, pooled_prior_snapshot_id
- GLM_fallback_probs, GLM_fallback_agreement_flag
- ensemble_probs, ensemble_agreement
- p10/p50/p90, p_final_sd, quantile_width
- gating_reasons, routing_decision (auto/priority_audit)
- scorer_version, calibrator_version, provenance_hash

K. Initial hyperparameters (start values; sweepable)
- TOP1_DOM_THRESHOLD = 0.60
- TOP1_SPEND_HIGH = 400
- BATCH_FRAGILE_THRESHOLD = 0.05 (5%)
- N_min_slice = 50 (dom_high), 25 (other fragiles)
- Z_high = 0.85 (dom_high/cryo_all_zero), 0.80 (others)
- A_high = 0.995 (ensemble agreement)
- SE_accept = 0.06 general (dom_high/cryo_all_zero require stronger consensus)
- QW_accept (p90−p10) = 0.12 (dom_high/cryo_all_zero) – 0.18 (others)
- CAP_PER_FEATURE_LOGIT = 3.0
- κ_dom = 0.10; κ_zero_cryo = 0.12; κ_miss = 0.05
- N0_dom_channel = 75; N0_all_zero_cryo = 100

L. CI canaries & expected behavior
- 0160_01 (RoomService = 4119, top1_dom_flag True):
  - Expected: route -> priority_audit unless slice_context_score ≥ Z_high AND GLM & ensemble consensus AND se_combined ≤ SE_accept.
- 0163_01 (all-zero + CryoSleep True):
  - Expected: route -> priority_audit unless cryo_all_zero pooled-prior and slice_context_score give high confidence AND GLM agrees.
- Other prior canaries preserved: 0152_01, 0151_01, 0144_01, 0148_01, 0149_01.

Why this will reduce batch errors (short)
- Fragile gating prevents overconfident auto-decisions for single-record novel slices (dom_high, all_zero+CryoSleep).
- Dominant-channel-aware pooled priors and larger N0 for fragile slices prevent a single record from overturning stable priors.
- var_dom_high / var_all_zero_cryo increase calibrated uncertainty for brittle slices; gate requires consensus before auto-deciding.
- Per-feature logit caps and dominance-scaling stop single features from flipping predictions.
- Standardized transforms + persisted provenance remove mismatch bugs across scorer/calibrator/gate.
- Retraining with upweighted contradictions corrects directionality and reduces future brittle errors.

Immediate one-line corrective action
- Deploy n==1 gating: route any record with top1_share ≥ 0.60 OR top1_spend ≥ 400 OR cryo_all_zero_flag OR all_zero_flag OR missingness_count ≥ 2 to priority_audit unless context_score ≥ 0.85 AND GLM_fallback & ensemble consensus AND se_combined ≤ 0.06 — add 0160_01, 0163_01, 0152_01, 0151_01, 0144_01, 0148_01, 0149_01 to canaries.

Next steps / offer
I can deliver either (pick one):
1) Minimal gating patch: pseudocode + CI unit tests + deploy checklist to block fragile n==1 auto-decisions and add canaries (ready in 2–12 hours).
2) Full retrain & deployment plan: dataset selection, upweighting schedule, CV folds, hyperparameter sweeps, acceptance criteria, dashboards + 14–28 day shadow-run plan (ready in 24–48 hours).

If you want the minimal patch now I will produce the exact pseudocode, unit tests, and a deploy checklist. If you prefer the full retrain plan I’ll prepare the training recipe, CV splits, upweight schedule for contradictions, and the shadow-run dashboard definitions. Which do you want first?

============================================================